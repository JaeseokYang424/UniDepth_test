import sys
import os
import torch
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image

# --- [1] ê²½ë¡œ ë° í™˜ê²½ ë³€ìˆ˜ ì„¤ì • ---
UNI_ENGINE_DIR = "/data2/hojun/UniDepth"
if UNI_ENGINE_DIR not in sys.path:
    sys.path.append(UNI_ENGINE_DIR)

os.environ["TORCH_HOME"] = "/data2/hojun/torch_cache"
os.environ["HUGGINGFACE_HUB_CACHE"] = "/data2/hojun/torch_cache"
os.environ["TF_CPP_MIN_LOG_LEVEL"] = "3"

# --- [2] ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ---
try:    
    from unidepth.models import UniDepthV2
    print("âœ… UniDepth ì—”ì§„ ë¡œë“œ ì„±ê³µ!")
except ImportError:
    print(f"âŒ UniDepth ì—”ì§„ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”: {UNI_ENGINE_DIR}")
    sys.exit(1)

import tensorflow as tf
import tensorflow_datasets as tfds
tf.config.set_visible_devices([], 'GPU')

# --- [3] ë¡œì»¬ OXE ë°ì´í„° ë¡œë“œ í•¨ìˆ˜ ---
def get_local_oxe_image():
    local_path = "/data2/hojun/oxe/cmu_play_fusion"
    try:
        builder = tfds.builder_from_directory(local_path)
        ds = builder.as_dataset(split='train')
        for episode in ds.take(1):
            for step in episode['steps'].take(1):
                img_array = step['observation']['image'].numpy()
                return Image.fromarray(img_array).convert("RGB")
    except Exception as e:
        print(f"âŒ ë°ì´í„°ì…‹ ë¡œë“œ ì—ëŸ¬: {e}")
        return None

# --- [4] ë©”ì¸ ì¶”ë¡  ë° ì°¨ì› í™•ì¸ ---
def main():
    DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    SAVE_PATH = "/data2/hojun/UniDepth_test/oxe_unidepth_test_result.png"

    # 1. ëª¨ë¸ ë¡œë“œ
    print("ğŸš€ UniDepthV2 (ViT-L) ëª¨ë¸ ë¡œë”© ì¤‘...")
    model = UniDepthV2.from_pretrained("lpiccinelli/unidepth-v2-vitl14").to(DEVICE)
    model.eval()

    # 2. ì´ë¯¸ì§€ ì¤€ë¹„
    raw_img = get_local_oxe_image()
    if raw_img is None: return

    # ---------------------------------------------------------
    # [ì¶”ê°€] Backbone(Latent Vector) ì°¨ì› í™•ì¸ ë£¨í‹´
    # ---------------------------------------------------------
    print("\nğŸ” [Backbone ë¶„ì„ ì‹œì‘]")
    # ì¸ì½”ë”ëŠ” 14ì˜ ë°°ìˆ˜ ì…ë ¥ì„ ì›í•˜ë¯€ë¡œ ë‚´ë¶€ì™€ ë™ì¼í•˜ê²Œ 518ë¡œ ë¦¬ì‚¬ì´ì§•
    input_size = (518, 518)
    img_for_backbone = raw_img.resize(input_size, Image.BILINEAR)
    
    # í…ì„œ ë³€í™˜ ë° ë°°ì¹˜ ì°¨ì› ì¶”ê°€
    test_tensor = torch.from_numpy(np.array(img_for_backbone)).permute(2, 0, 1).unsqueeze(0).float().to(DEVICE)
    test_tensor = test_tensor / 255.0 # ê¸°ë³¸ì ì¸ ìŠ¤ì¼€ì¼ë§
    
    with torch.no_grad():
        # ì•„ê¹Œ êµ¬ì¡° í™•ì¸ ê²°ê³¼ì— ë”°ë¼ 'pixel_encoder' ì§ì ‘ í˜¸ì¶œ
        # n=1: ë§ˆì§€ë§‰ ë¸”ë¡, reshape=True: [B, C, H, W] í˜•íƒœ ë³€í™˜
        latent_vector = model.pixel_encoder.get_intermediate_layers(test_tensor, n=1, reshape=True)[0]
    
    print(f"   - ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°: {raw_img.size}")
    print(f"   - ì¸ì½”ë” ì…ë ¥ í¬ê¸°: {test_tensor.shape}")
    print(f"   - ìµœì¢… Latent Vector ì°¨ì›: {latent_vector.shape}")
    print("====================================================\n")
    # ---------------------------------------------------------

    # 3. ê¸°ì¡´ ì¶”ë¡  (Inference)
    input_tensor = torch.from_numpy(np.array(raw_img)).permute(2, 0, 1).to(DEVICE)
    print("ğŸ¤– UniDepth ì „ì²´ ì¶”ë¡  ìˆ˜í–‰ ì¤‘...")
    with torch.no_grad():
        predictions = model.infer(input_tensor)
        depth = predictions["depth"].squeeze().cpu().numpy()
        confidence = predictions["confidence"].squeeze().cpu().numpy()

    # 4. ê²°ê³¼ ì‹œê°í™” ë° ì €ì¥
    plt.figure(figsize=(15, 5))
    plt.subplot(1, 3, 1); plt.imshow(raw_img); plt.title("Original"); plt.axis("off")
    plt.subplot(1, 3, 2); im1 = plt.imshow(depth, cmap='magma'); plt.title("Depth"); plt.colorbar(im1); plt.axis("off")
    plt.subplot(1, 3, 3); im2 = plt.imshow(confidence, cmap='viridis'); plt.title("Confidence"); plt.colorbar(im2); plt.axis("off")
    plt.tight_layout()
    plt.savefig(SAVE_PATH)
    print(f"âœ… ì‹œê°í™” ì™„ë£Œ: {SAVE_PATH}")

if __name__ == "__main__":
    main()
